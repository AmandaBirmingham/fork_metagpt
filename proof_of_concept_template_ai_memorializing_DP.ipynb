{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bf2ceed-c428-495f-89e5-af098068436f",
   "metadata": {},
   "source": [
    "# AI-driven Interactive Metadata \n",
    "\n",
    "*Amanda Birmingham, Dept. of Pediatrics, UC San Diego*\n",
    "\n",
    "A natural-language approach to metadata investigation and cleaning using the `ChatGPT 4` LLM, the `Langchain` AI framework, and AI-based speech recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867665e1-ae64-4022-9b46-b770257625a5",
   "metadata": {},
   "source": [
    "## Initial set-up\n",
    "\n",
    "To be performed outside notebook:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ab57d74-89f5-435c-85bb-604bde04c370",
   "metadata": {},
   "source": [
    "brew install portaudio"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c71a3839-f742-453d-a840-ad5acb4f826a",
   "metadata": {},
   "source": [
    "conda create -n metagpt_langchain python=3.10 pandas numpy \n",
    "conda activate metagpt_langchain "
   ]
  },
  {
   "cell_type": "raw",
   "id": "650cd2d5-3b55-4362-80b1-07888119252a",
   "metadata": {},
   "source": [
    "pip install pyaudio \n",
    "pip install speechrecognition"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b6bc199-7eb5-4246-b1ce-8d3b7ad80393",
   "metadata": {},
   "source": [
    "pip install ipylab"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e47f9cfd-e77d-4d92-87de-baec00ccac48",
   "metadata": {},
   "source": [
    "pip install openai\n",
    "pip install langchain\n",
    "pip install langchain-community\n",
    "pip install --upgrade --quiet langchain langgraph"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8877dee9-051d-4289-ad2e-b1bf4ed31c90",
   "metadata": {},
   "source": [
    "# if using OpenAI/ChatGPT\n",
    "pip install --upgrade --quiet langchain-openai\n",
    "export OPENAI_API_KEY=<YOUR_OPENAI_API_KEY>\n",
    "source ~/.bashrc"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e290c3b-fda4-4904-890c-b29bc6a48f55",
   "metadata": {},
   "source": [
    "# if using Google Gemini\n",
    "pip install -qU langchain-google-genai\n",
    "export GOOGLE_API_KEY=<YOUR_GOOGLE_API_KEY>\n",
    "source ~/.bashrc"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1e4bfb9-fcbc-4030-bd50-778208bc9a38",
   "metadata": {},
   "source": [
    "conda install click flake8 nose pep8 pyyaml \n",
    "pip install cerberus \n",
    "pip install https://github.com/AmandaBirmingham/qiimp2.git"
   ]
  },
  {
   "cell_type": "raw",
   "id": "99a7159f-be1d-49f3-8515-d18e9d6f677b",
   "metadata": {},
   "source": [
    "jupyter lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a1de0-3929-42bd-82f3-9765f92e9d47",
   "metadata": {},
   "source": [
    "## Adjustable LLM settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b03f4a-06fe-47b1-bffa-b5296d58a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "g_GEMINI = \"GOOGLE_API_KEY\"\n",
    "g_CHATGPT = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "g_chosen_llm = g_CHATGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4821e763-8c0a-445f-83df-6d6cd5188e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_use_speech = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56954c9f-20ac-4174-9a24-d6a202f15238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: Increasing this number will increase the amount of information included in each \n",
    "# LLM query and thus increase the cost of the queries!\n",
    "# Decreasing this number will make the LLM forget past exchanges more quickly\n",
    "g_num_msgs_in_history = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9393f1f-21b0-479d-b8c3-d7b32fbc0098",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_base_prompt = f\"using pandas 3 and python 3.10+ to clean data in jupyter lab.\"\n",
    "g_ds_prompt = f\"You are a data scientist {g_base_prompt}\"\n",
    "g_pf_prompt = f\"You are a professor of data science teaching a class on {g_base_prompt}.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19e9df2-6426-477d-acab-44cb507d7437",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9a4660-e907-4c3d-a316-7f4955f668c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afd405e-8388-489b-9964-ede6a17a0758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython import get_ipython\n",
    "from IPython.display import display\n",
    "from traitlets import observe, link, Unicode, Bool, Any\n",
    "#from itables import init_notebook_mode, show\n",
    "from ipylab import JupyterFrontEnd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c04154e-df07-4647-aa67-3b6eae1f6f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as speech_recog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9df0b1-a3df-4b73-b738-f6d2f0e2664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import trim_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72117e1b-9bd5-4b0f-b46f-6041860a191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiimp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1bcc65-1a37-4654-b481-6a5634b5ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f90cad-01a0-4ade-9477-fb9c5537bda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "logging.basicConfig(level=logging.WARNING, format='%(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b9033b-2f2c-4755-b9fd-c52080467c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053fc47c-b149-4762-aaa6-e202d7254f91",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d2e118-c031-440c-90d5-88809565b5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert g_chosen_llm in os.environ, f\"Please set the {g_chosen_llm} environment variable.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc260557-12de-4bf5-b20a-1698d3dab02c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if g_chosen_llm == g_CHATGPT:\n",
    "    from langchain_openai import ChatOpenAI\n",
    "    _g_chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "elif g_chosen_llm == g_GEMINI:\n",
    "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "    _g_chat_model = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-1.5-pro\",\n",
    "        temperature=0,\n",
    "        max_tokens=None,\n",
    "        timeout=None,\n",
    "        max_retries=2,\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"Unrecognized llm model '{g_chosen_llm}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39a5e8f-0cdb-49cf-953d-2c8ef667c327",
   "metadata": {},
   "source": [
    "## Chat creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f5925e-94dd-45c5-9d9d-b012f14183cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _start_chat(model, custom_prompt):    \n",
    "    # Define trimmer\n",
    "    # count each message as 1 \"token\" (token_counter=len) and \n",
    "    #keep only the last x messages\n",
    "    trimmer = trim_messages(strategy=\"last\", max_tokens=g_num_msgs_in_history, \n",
    "                            token_counter=len)\n",
    "    \n",
    "    workflow = StateGraph(state_schema=MessagesState)\n",
    "    \n",
    "    # Define the function that calls the model\n",
    "    def call_model(state: MessagesState):\n",
    "        trimmed_messages = trimmer.invoke(state[\"messages\"])\n",
    "        system_prompt = custom_prompt\n",
    "        messages = [SystemMessage(content=system_prompt)] + trimmed_messages\n",
    "        response = model.invoke(messages)\n",
    "        return {\"messages\": response}\n",
    "    \n",
    "    \n",
    "    # Define the node and edge\n",
    "    workflow.add_node(\"model\", call_model)\n",
    "    workflow.add_edge(START, \"model\")\n",
    "    \n",
    "    # Add simple in-memory checkpointer\n",
    "    memory = MemorySaver()\n",
    "    app = workflow.compile(checkpointer=memory)\n",
    "    return app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5085a89a-c08b-45cb-9688-a80ecf1f77dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_g_chat = _start_chat(_g_chat_model, g_ds_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a26535-1ca0-426e-8d83-e4638988e646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AB: Moved front end helpers later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a2dda8-43d5-4475-8bce-0e720dcd7716",
   "metadata": {},
   "source": [
    "## Prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34c83fd-c6d9-4272-8864-5918bbe5928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai helper prompts\n",
    "g_unique_set_prefix = \"for column named\"\n",
    "g_col_check_prefix = \"check column named\"\n",
    "g_code_prefix = \"write code to\"\n",
    "\n",
    "# AB: modified and extended\n",
    "# function helper prompts\n",
    "g_summarize_statement = \"summarize table\"\n",
    "g_summarize_col_statement = \"summarize column named\"\n",
    "g_explore_col_statement = \"explore column named\"\n",
    "\n",
    "# button prompts\n",
    "g_add_cell_statement = \"add cell\"\n",
    "g_copy_last_statement = \"copy it\"\n",
    "g_run_last_statement = \"now run it\"\n",
    "g_revert_df_statement = \"revert dataframe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc761687-6730-4dcb-81e4-3c3b0ca75bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _remove_known_str(a_prompt, known_str):\n",
    "    return a_prompt.replace(known_str, \"\").strip()\n",
    "\n",
    "\n",
    "def _change_first_char(a_str, upper=True):\n",
    "    if upper:\n",
    "        a_lambda = lambda x: x.groups()[0].upper()\n",
    "    else:\n",
    "        a_lambda = lambda x: x.groups()[0].lower()\n",
    "        \n",
    "    # affect ONLY first letter, leave all the rest alone\n",
    "    # (so different that a_str.capitialize() or a_str.title())\n",
    "    return re.sub('([a-zA-Z])', a_lambda, a_str, 1)   \n",
    "\n",
    "\n",
    "def _expand_prompt(user_prompt, df_name, a_df):\n",
    "    df_prompt = f\"You are given the '{df_name}' dataframe with columns {list(a_df.columns)}. \"\n",
    "    \n",
    "    if user_prompt.startswith(g_col_check_prefix):\n",
    "        col_name = _remove_known_str(user_prompt, g_col_check_prefix)\n",
    "        col_name = col_name.replace(\" \", \"_\")\n",
    "        user_prompt = _get_explore_col_prompt(col_name)     \n",
    "    # end if starts with check prefix--which itself adds a unique set prefix\n",
    "    \n",
    "    if user_prompt.startswith(g_unique_set_prefix):\n",
    "        new_prompt = _get_unique_set_prompt(user_prompt, a_df)\n",
    "    elif user_prompt.startswith(g_code_prefix):\n",
    "        new_prompt = _get_code_prompt(user_prompt)        \n",
    "    else:\n",
    "        new_prompt = user_prompt\n",
    "\n",
    "    new_prompt = df_prompt + new_prompt\n",
    "\n",
    "    return new_prompt\n",
    "\n",
    "\n",
    "def _get_explore_col_prompt(col_name):\n",
    "    explore_prompt = \"suggest the appropriate Pandas data type for the values in this column, very briefly hypothesize about what they represent, and indicate if any look invalid or unexpected.\" # Please keep responses short and to the point.\"\n",
    "    col_prompt = f\"{g_unique_set_prefix} {col_name}, {explore_prompt}\"\n",
    "    return col_prompt\n",
    "\n",
    "\n",
    "def _get_unique_set_prompt(user_prompt, a_df):\n",
    "    err_msg = f\"Please phrase your question as {g_unique_set_prefix} <col_name>, <question about unique values of column>\"\n",
    "    \n",
    "    if not user_prompt.startswith(g_unique_set_prefix):\n",
    "        return err_msg\n",
    "\n",
    "    prompt_split = user_prompt.split(\",\")\n",
    "    if len(prompt_split) < 2:\n",
    "        return err_msg\n",
    "\n",
    "    col_name = prompt_split[0].replace(g_unique_set_prefix, \"\").strip()\n",
    "    new_prompt = f\"For the column named '{col_name}' containing the set of values  {set(a_df[col_name])}, {','.join(prompt_split[1:])}\"\n",
    "    return new_prompt\n",
    "\n",
    "\n",
    "def _get_code_prompt(user_prompt):\n",
    "    err_msg = f\"Please phrase your question as {g_code_prefix} <perform some operation>\"\n",
    "    \n",
    "    if not user_prompt.startswith(g_code_prefix):\n",
    "        return err_msg\n",
    "\n",
    "    new_prompt = f\"{user_prompt} Do not include any non-comment explanations, import statements, or the instantiation of the dataframe. Do not include markdown formatting in your output. Provide runnable code as output.\"\n",
    "    return new_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a62c2c-ebe1-4148-9f7d-529fbc435bcb",
   "metadata": {},
   "source": [
    "## State management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e297ff8d-4981-498d-ad12-1dc2b08f61d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_g_last_code_out = {}\n",
    "_g_last_working_df = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc4b5c2-8abb-4729-850d-fb4cfe9a290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_g_LAST_CODE_NAME = \"AI-generated code\"\n",
    "_g_LAST_DF_NAME = \"g_working_df\"   \n",
    "\n",
    "# AB: added get-default functions\n",
    "def _get_df_name(df_name):\n",
    "    return df_name if df_name is not None else _g_LAST_DF_NAME\n",
    "\n",
    "\n",
    "# TODO: this could be used to replace a lot of existing checks\n",
    "def _get_df(a_df):\n",
    "    return a_df if a_df is not None else g_working_df\n",
    "\n",
    "\n",
    "def _save_state(state_dict, obj_to_save, state_name, use_last_execution_num=False):\n",
    "    # this does NOT copy the input obj_to_save before saving it--that should happen outside this call, if needed\n",
    "    execution_num = get_ipython().execution_count\n",
    "    if use_last_execution_num:\n",
    "        execution_num = execution_num - 1\n",
    "    \n",
    "    if execution_num in state_dict:\n",
    "        warnings.warn(f\"{state_name} already contains state for a cell with execution number {execution_num}, which will be overwritten.\")\n",
    "    state_dict[execution_num] = obj_to_save\n",
    "    return state_dict\n",
    "\n",
    "\n",
    "def _get_last_state(state_dict):\n",
    "    last_value = None\n",
    "    if state_dict is not None and len(state_dict)>0:\n",
    "        last_key, last_value = next(reversed(state_dict.items()))\n",
    "    return last_value\n",
    "\n",
    "\n",
    "def _df_changed():\n",
    "    #print(\"in _df_changed\")\n",
    "    last_working_df = _get_last_state(_g_last_working_df)\n",
    "\n",
    "    if last_working_df is not None:\n",
    "        #print(f\"g_working_df cols: {g_working_df.columns}\")\n",
    "        #print(f\"last_working_df cols: {last_working_df.columns}\")\n",
    "        if not last_working_df.equals(g_working_df):\n",
    "            #print(\"are different\")\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def _revert_df():\n",
    "    global g_working_df\n",
    "    msg = f\"There is no {_g_LAST_DF_NAME} state stored.\" \n",
    "\n",
    "    last_working_df = _get_last_state(_g_last_working_df)\n",
    "    if last_working_df is not None:\n",
    "        if _df_changed():\n",
    "            store_working_df()\n",
    "            g_working_df = last_working_df\n",
    "            msg = f\"{_g_LAST_DF_NAME} reverted to last saved state.\"\n",
    "        else:\n",
    "            msg = f\"{_g_LAST_DF_NAME} has not changed since last saved state.\"\n",
    "    return msg\n",
    "\n",
    "\n",
    "def store_working_df(a_df=None, use_last_execution_num=False):\n",
    "    if a_df is None:\n",
    "        a_df = g_working_df.copy()\n",
    "    _save_state(_g_last_working_df, a_df, _g_LAST_DF_NAME, use_last_execution_num=use_last_execution_num)\n",
    "\n",
    "\n",
    "def revert_df():\n",
    "    statement = _revert_df()\n",
    "    return statement\n",
    "\n",
    "\n",
    "# decorator\n",
    "def stateful(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        if _df_changed():\n",
    "            store_working_df(use_last_execution_num=True)\n",
    "        func(*args, **kwargs)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70863b51-c18f-46a8-b410-a1d607848283",
   "metadata": {},
   "source": [
    "## Front-end helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157f9ff1-2058-43fb-8979-2a25e9c3eba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_g_front_end = JupyterFrontEnd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a82240-b933-40ed-a7e5-d53fed07573c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _set_raw():\n",
    "    _g_front_end.commands.execute('notebook:change-cell-to-raw')\n",
    "    \n",
    "\n",
    "def _insert_and_populate(statement=None, move_up=True):\n",
    "    _g_front_end.commands.execute('notebook:insert-cell-below')\n",
    "    if statement is not None:\n",
    "        time.sleep(0.2)\n",
    "        _g_front_end.commands.execute('notebook:replace-selection', { 'text': statement})\n",
    "        _g_front_end.commands.execute('notebook:enter-edit-mode')\n",
    "\n",
    "    if move_up:\n",
    "        _g_front_end.commands.execute('notebook:move-cell-up') \n",
    "        \n",
    "\n",
    "def _insert_and_run(statement=None, move_up=True):\n",
    "    _insert_and_populate(statement, move_up)\n",
    "    \n",
    "    if statement is not None:\n",
    "        _g_front_end.commands.execute('notebook:run-cell-and-select-next')  \n",
    "        _g_front_end.commands.execute('notebook:enter-edit-mode')\n",
    "\n",
    "\n",
    "# AB: new\n",
    "def _set_query_to_raw(up_twice=False):\n",
    "    # move the cursor up to the query cell (the one running right now)\n",
    "    # and set *it* to raw\n",
    "    _g_front_end.commands.execute('notebook:move-cursor-up')\n",
    "    if up_twice:\n",
    "        _g_front_end.commands.execute('notebook:move-cursor-up')\n",
    "    _set_raw()\n",
    "\n",
    "    # move the cursor down TWICE: once from the query cell to the\n",
    "    # cell holding its output (either a raw cell or a created code cell), \n",
    "    # and once more to whatever comes next\n",
    "    _g_front_end.commands.execute('notebook:move-cursor-down')\n",
    "    _g_front_end.commands.execute('notebook:move-cursor-down')    \n",
    "\n",
    "\n",
    "def _set_query_and_output_to_raw(output):\n",
    "    # creates a (code) cell containing the (non-code) output;\n",
    "    # cursor is now on that new cell\n",
    "    _insert_and_populate(output)\n",
    "\n",
    "    # change now-current (new) cell to raw format\n",
    "    _set_raw()\n",
    "\n",
    "    _set_query_to_raw()\n",
    "\n",
    "\n",
    "def _set_query_to_raw_and_run_code_cell(code_str):\n",
    "    # print(code_str)\n",
    "    _save_state(_g_last_code_out, code_str, _g_LAST_CODE_NAME)    # This isn't working correctly\n",
    "    _insert_and_run(code_str, move_up=True)\n",
    "    _set_query_to_raw(up_twice=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdc04f9-b069-401d-8cfe-ce93d19571a8",
   "metadata": {},
   "source": [
    "## Chat helper function creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7f3e8d-f229-4d0e-8285-3abdc2387b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating an empty notebook allows prompt methods to bind to the \n",
    "# variable so the can use the real contents later without needing to be \n",
    "# passed an argument\n",
    "g_working_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f96d72c-b0c6-41fe-8573-fa04dc3e6ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AB: reordered\n",
    "@stateful\n",
    "def find_problem_headers(a_df=None):\n",
    "    a_df = a_df if a_df is not None else g_working_df\n",
    "\n",
    "    invalid_cols = a_df.columns[a_df.columns.str.contains(r'[^a-zA-Z0-9._ ]', regex=True)]\n",
    "    if len(invalid_cols) == 0:\n",
    "        out = \"No invalid column headers found.\"\n",
    "    else:\n",
    "        out = invalid_cols\n",
    "    print(out)\n",
    "\n",
    "\n",
    "@stateful\n",
    "def scrub_headers(a_df=None, lcase_headers=True):\n",
    "    a_df = a_df if a_df is not None else g_working_df\n",
    "\n",
    "    a_df.columns = a_df.columns.str.replace(r'[^a-zA-Z0-9]', '_', regex=True)  \n",
    "    a_df.columns = a_df.columns.str.replace(r'__+', '_', regex=True)  \n",
    "    a_df.columns = a_df.columns.str.strip('_')\n",
    "    if lcase_headers:\n",
    "        a_df.columns = a_df.columns.str.lower()\n",
    "    print(a_df.columns)\n",
    "\n",
    "\n",
    "@stateful\n",
    "def find_problem_records(a_df=None):\n",
    "    a_df = a_df if a_df is not None else g_working_df\n",
    "\n",
    "    # get records with leading or trailing spaces in any field\n",
    "    problem_records = a_df[a_df.apply(lambda x: x.str.contains(r'^\\s|\\s$', na=False).any(), axis=1)]\n",
    "    if len(problem_records) == 0:\n",
    "        print(\"No problem records found.\")\n",
    "    else:\n",
    "        display(problem_records)\n",
    "        return problem_records\n",
    "\n",
    "\n",
    "@stateful\n",
    "def scrub_problem_records():\n",
    "    global g_working_df\n",
    "    \n",
    "    # Remove leading or trailing spaces from any field in the dataframe\n",
    "    g_working_df = g_working_df.map(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "    print(\"Problem records scrubbed.\")\n",
    "\n",
    "\n",
    "# AB: modified params list, added line for input coltype, modified wording for df coltype\n",
    "def _deterministic_summarize_col(col_name, col_type_names, a_df=None, max_items_shown=None, visualize=True):\n",
    "    a_df = _get_df(a_df)\n",
    "    max_items_shown = max_items_shown if max_items_shown is not None else 10\n",
    "    \n",
    "    lines = []\n",
    "    lines.append(f\"{col_name}\")\n",
    "    lines.append(\"================\")\n",
    "    lines.append(f\"{col_type_names[col_name]} type\")\n",
    "    a_col = a_df[col_name]\n",
    "    \n",
    "    summary = []\n",
    "    col_uniques = a_col.unique()\n",
    "    count_uniques = len(col_uniques)\n",
    "    if a_col.is_unique:\n",
    "        summary.append(f\"All {count_uniques} values are unique.\")\n",
    "    else: \n",
    "        summary.append(f\"There are {count_uniques} unique value(s) in {len(a_col)} total values.\")\n",
    "    # end if all are unique\n",
    "        \n",
    "    caveat = f\"first {max_items_shown} \" if count_uniques > max_items_shown else \"\"\n",
    "    summary.append(f\"The {caveat}unique value(s):{col_uniques[:max_items_shown]}.\")\n",
    "    lines.append(\" \".join(summary))\n",
    "\n",
    "    lines.append(f\"The current dataframe datatype is {a_col.dtype}.\")\n",
    "    lines.append(\" \")\n",
    "\n",
    "    stats, plot = stats_from_col(col_name, col_type_names, a_df, max_items_shown, visualize)\n",
    "    lines.extend(stats)\n",
    "    return lines, plot\n",
    "\n",
    "\n",
    "def stats_from_col(col_name, col_type_names, a_df, max_items_shown, visualize):\n",
    "\n",
    "    type_of = col_type_names[col_name]\n",
    "\n",
    "    stats = [] # List of lines\n",
    "    if type_of == 'categorical':\n",
    "        stats += categorical_stats(col_name, a_df)\n",
    "        plot = visualize_col_categorical(col_name, a_df)\n",
    "\n",
    "    elif type_of == 'numeric':\n",
    "        stats += numeric_stats(col_name, a_df)\n",
    "        plot = visualize_col_numeric(col_name, a_df)\n",
    "\n",
    "    elif type_of == 'identifier':\n",
    "        stats += id_stats(col_name, a_df)\n",
    "        plot = None\n",
    "\n",
    "    stats.append('\\n')\n",
    "    \n",
    "    return stats, plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786993a2-65ff-41de-8ff5-c52e17c49f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AB: moved some private _ask functions up up here to allow\n",
    "# earlier use, added a few\n",
    "def _ask(user_prompt, df_name=None, a_df=None):\n",
    "    df_name = _get_df_name(df_name)\n",
    "    a_df = _get_df(a_df)\n",
    "    \n",
    "    new_prompt = _expand_prompt(user_prompt, df_name, a_df)    \n",
    "    result = _g_chat.invoke(\n",
    "        {\"messages\": [HumanMessage(content=new_prompt)]},\n",
    "        config={\"configurable\": {\"thread_id\": \"1\"}},\n",
    "    )\n",
    "    return new_prompt, result\n",
    "\n",
    "def _get_result_text(a_result):\n",
    "    return a_result.get(\"messages\")[-1].content\n",
    "\n",
    "\n",
    "def _clean_answer(answer_str):\n",
    "    answer_str = re.sub(\"^```python\\n\", \"\", answer_str)\n",
    "    answer_str = re.sub(\"\\n```$\", \"\", answer_str)   \n",
    "    return answer_str\n",
    "    \n",
    "\n",
    "def _get_ask_txt(ask_result):  \n",
    "    output = _get_result_text(ask_result)\n",
    "    output = _clean_answer(output) \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f76520-e590-407d-8124-2f3c667278b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AB: Placeholder for DP's ai-type-guessing function\n",
    "# TODO: replace\n",
    "\n",
    "_id_type = 'identifier'\n",
    "_cat_type = 'categorical'\n",
    "_num_type = 'numeric'\n",
    "\n",
    "# def _ai_get_col_types(df_name, a_df, col_names_list=None):\n",
    "#     return {\"sample_name\":\"string\", \"subjectid\": \"string\", \"body_site\": \"string\", \"age\": \"numeric\", \"sex\": \"string\"}\n",
    "\n",
    "def _ai_get_col_type_one(col_name, a_df=None, df_name=None):\n",
    "    \n",
    "    col = a_df[col_name]\n",
    "    _, result = _ask(f'based on the following entries: {col}, in a column named {col_name} '\n",
    "            f'is this categorical or numeric or identifier. Give a one word answer '\n",
    "            f'either categorical or numeric or identifier.',\n",
    "            df_name=df_name, a_df=a_df)\n",
    "\n",
    "    t = _get_result_text(result)\n",
    "\n",
    "    col_type = _id_type\n",
    "    for poss_type in [_num_type, _cat_type]:\n",
    "    \tif poss_type in t.lower():\n",
    "    \t\tcol_type = poss_type\n",
    "    \t\tbreak\n",
    "\n",
    "    return col_type\n",
    "\n",
    "\n",
    "def _ai_get_col_types(df_name, a_df, col_names_list=None):\n",
    "\n",
    "    df_name = _get_df_name(df_name)\n",
    "    a_df = _get_df(a_df)\n",
    "    \n",
    "    # Ignore warnings generated by multiple calls to ask from the same cell\n",
    "    # warnings.filterwarnings('ignore')\n",
    "\n",
    "    col_types = {}\n",
    "    for col_name in a_df.columns:\n",
    "\n",
    "        col_type = _ai_get_col_type_one(col_name, a_df=a_df, df_name=df_name)\n",
    "\n",
    "        col_types[col_name] = col_type\n",
    "\n",
    "    return col_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6478b7f-d8e9-4f91-9d33-168f7d393fdb",
   "metadata": {},
   "source": [
    "## Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679cae9d-b3b2-4eb2-b22b-55e9e7af4c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AB: Separated from contents of earlier deterministic prompts cell for clarity \n",
    "def _get_coltypes_str(col_types, col_names_list=None):\n",
    "    if col_names_list == None:\n",
    "        col_names_list = list(col_types.keys())\n",
    "        \n",
    "    min_col_types = {k: v for k, v in col_types.items() if k in col_names_list}\n",
    "    min_coltypes_str = \"{\" + \", \".join(f'\"{key}\": \"{value}\"' for key, value \n",
    "                                   in min_col_types.items()) + \"}\"\n",
    "    return min_coltypes_str\n",
    "\n",
    "\n",
    "def _get_ai_coltypes_str(df_name, a_df, col_names_list=None):\n",
    "    col_types = _ai_get_col_types(df_name, a_df, col_names_list)\n",
    "    coltypes_str = _get_coltypes_str(col_types, col_names_list)\n",
    "    return coltypes_str\n",
    "\n",
    "\n",
    "def _ai_summarize_col(col_name, df_name, a_df, max_items_shown=None, visualize=True):\n",
    "    one_coltypes_str = _get_ai_coltypes_str(df_name, a_df, col_names_list=[col_name])\n",
    "    result = f\"summarize_col('{col_name}', {one_coltypes_str}, df_name='{df_name}', a_df={df_name}, max_items_shown={max_items_shown}, visualize={visualize})\"\n",
    "    _set_query_to_raw_and_run_code_cell(result)\n",
    "    # return result\n",
    "\n",
    "\n",
    "def _ai_summarize(df_name, a_df, max_items_shown=None, visualize=False):\n",
    "    coltypes_str = _get_ai_coltypes_str(df_name, a_df)\n",
    "    result = f\"summarize(col_types={coltypes_str}, df_name='{df_name}', a_df={df_name}, max_items_shown={max_items_shown}, visualize={visualize})\"\n",
    "    _set_query_to_raw_and_run_code_cell(result)\n",
    "\n",
    "\n",
    "def _validate_column(col_name, a_df, df_name):\n",
    "    if col_name not in a_df.columns:\n",
    "        raise ValueError(f'Column {col_name} not found in {df_name}')\n",
    "\n",
    "@stateful\n",
    "def summarize_col(col_name, col_types=None, df_name=None, a_df=None, max_items_shown=None, visualize=True):\n",
    "    df_name = _get_df_name(df_name)\n",
    "    a_df = _get_df(a_df)\n",
    "    \n",
    "    _validate_column(col_name, a_df, df_name)\n",
    "    \n",
    "    if col_types is None:\n",
    "        _ai_summarize_col(col_name, df_name, a_df, max_items_shown, visualize=visualize)\n",
    "    else:\n",
    "        result, plot = _deterministic_summarize_col(col_name, col_types, a_df, max_items_shown, visualize=visualize)\n",
    "        result_str = \"\\n\".join(result)\n",
    "        print(result_str)\n",
    "        if visualize:\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "@stateful\n",
    "def summarize(df_name=None, a_df=None, col_types=None, max_items_shown=None, visualize=False):\n",
    "    df_name = _get_df_name(df_name)\n",
    "    a_df = _get_df(a_df)\n",
    "\n",
    "    if col_types is None:\n",
    "        _ai_summarize(df_name, a_df, max_items_shown, visualize=visualize)\n",
    "    else:\n",
    "        result = [f\"The dataframe '{df_name}' has {len(a_df)} rows and {len(a_df.columns)} columns.\", \" \"]\n",
    "        for curr_col_name in a_df.columns:\n",
    "            curr_result, plot = _deterministic_summarize_col(\n",
    "                curr_col_name, col_types, a_df, max_items_shown, \n",
    "                visualize=visualize)\n",
    "            \n",
    "            result.extend(curr_result)\n",
    "            # next column\n",
    "            result_str = \"\\n\".join(result)\n",
    "            print(result_str)\n",
    "            if visualize:\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee63742a-ba84-4a37-960c-73d588eb4ceb",
   "metadata": {},
   "source": [
    "## Stats and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fc4d05-ef5e-4e02-8641-65ffbff8b2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Stats\n",
    "\n",
    "def categorical_stats(col_name, a_df):\n",
    "    \"\"\" Returns list of printable lines \"\"\"\n",
    "\n",
    "    col = a_df[col_name]\n",
    "    counts = col.value_counts().to_string()\n",
    "\n",
    "    lines = []\n",
    "    lines.append(f'Column {col_name} thought to be categorical.')\n",
    "    lines.append('------ Summary Statistics ------')\n",
    "    lines.append(counts+'\\n')\n",
    "    \n",
    "    return lines\n",
    "\n",
    "\n",
    "def numeric_stats(col_name, a_df):\n",
    "    \"\"\" Returns list of printable lines \"\"\"\n",
    "\n",
    "    # Drop nan values, coerce to numeric, then drop nans again\n",
    "    col = a_df[col_name]\n",
    "    new_col = pd.to_numeric(col.dropna(), errors='coerce')\n",
    "    new_col = new_col.dropna()\n",
    "    \n",
    "    MIN = min(new_col)\n",
    "    MAX = max(new_col)\n",
    "    MED = np.median(new_col)\n",
    "    \n",
    "    lines = []\n",
    "    lines.append(f'Column {col_name} thought to be numeric.')\n",
    "    lines.append('------ Summary Statistics ------')\n",
    "    lines.append(f'min: {MIN}\\nmax: {MAX}\\nmedian: {MED}\\n')\n",
    "    \n",
    "    return lines\n",
    "\n",
    "def id_stats(col_name, a_df):\n",
    "    \n",
    "    lines = [f'Column {col_name} thought to be identifier.\\n']\n",
    "    return lines\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6113c9-3b82-4ef3-959a-f22c9fe349b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualizations\n",
    "\n",
    "def visualize_col_categorical(col_name, df_name=None, a_df=None):\n",
    "    \"\"\"\n",
    "    Generates a bar plot for the value counts of a specified column.\n",
    "\n",
    "    Parameters:\n",
    "        col_name (str): The column to group by.\n",
    "        df_name (DataFrame): Name of dataframe if different than g_working_df.\n",
    "        a_df (DataFrame): Dataframe if differnt than g_working_df\n",
    "    \"\"\"\n",
    "\n",
    "    a_df = a_df if a_df is not None else g_working_df\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.barplot(x=a_df[col_name].value_counts().index, \n",
    "                y=a_df[col_name].value_counts().values,\n",
    "                ax=ax)\n",
    "    ax.set_title(f\"Value Counts for {col_name}\")\n",
    "    ax.set_ylabel(\"Counts\")\n",
    "    ax.set_xlabel(col_name)\n",
    "    ax.tick_params(axis='x', rotation=45)  # Method 2: Directly rotate ticks\n",
    "\n",
    "    return ax\n",
    "\n",
    "def visualize_col_numeric(col_name, df_name=None, a_df=None):\n",
    "    \"\"\"\n",
    "    Generates a bar plot for the value counts of a specified column.\n",
    "\n",
    "    Parameters:\n",
    "        col_name (str): The column to group by.\n",
    "        df_name (DataFrame): Name of dataframe if different than g_working_df.\n",
    "        a_df (DataFrame): Dataframe if differnt than g_working_df\n",
    "    \"\"\"\n",
    "\n",
    "    a_df = a_df if a_df is not None else g_working_df\n",
    "\n",
    "    df = a_df[[col_name]]\n",
    "    df[col_name] = pd.to_numeric(df[col_name], errors='coerce')\n",
    "    df = df.dropna()\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.kdeplot(\n",
    "       data=df, x=col_name,\n",
    "       fill=True, common_norm=False,\n",
    "       alpha=.5, linewidth=0, ax=ax\n",
    "    )\n",
    "    ax.set_title(f'{col_name}')\n",
    "    return ax\n",
    "\n",
    "\n",
    "def visualize_col(col_name, col_types, df_name=None, a_df=None):\n",
    "\n",
    "    a_df = _get_df(a_df)\n",
    "    df_name = _get_df_name(df_name)\n",
    "\n",
    "    _validate_column(col_name)\n",
    "    \n",
    "    type_of = col_types[col_name]\n",
    "\n",
    "    if type_of == 'categorical':\n",
    "        ax = visualize_col_categorical(col_name, a_df)\n",
    "        plt.show()\n",
    "\n",
    "    if type_of == 'numeric':\n",
    "        ax = visualize_col_numeric(col_name, a_df)\n",
    "        plt.show()\n",
    "\n",
    "    if type_of == 'identifier':\n",
    "        print(id_stats(col_name)[0])\n",
    "\n",
    "def visualize_two_cols_cc(col_name1, col_name2, df_name=None, a_df=None):\n",
    "    \n",
    "    a_df = _get_df(a_df)\n",
    "    df_name = get_df_name()\n",
    "\n",
    "    counts = a_df.groupby([col_name1, col_name2]).size().unstack(fill_value=0)\n",
    "    fig, ax = plt.subplots()\n",
    "    counts.plot(kind='bar', stacked=True, ax=ax)\n",
    "    ax.set_xlabel(col_name1)\n",
    "    ax.set_ylabel('Number of Observations')\n",
    "    ax.set_title(f'Observations by {col_name1} and {col_name2}')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def visualize_two_cols_cn(cat_col, num_col, df_name=None, a_df=None):\n",
    "    \"\"\"\n",
    "    Generates a histogram plot of the different values colored by category.\n",
    "    \"\"\"\n",
    "    a_df = _get_df(a_df)\n",
    "    df_name = _get_df_name(df_name)\n",
    "\n",
    "    df = a_df[[num_col, cat_col]]\n",
    "    df[num_col] = pd.to_numeric(df[num_col], errors='coerce')\n",
    "    df[cat_col] = df[cat_col].astype('category')\n",
    "    df = df.dropna()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.kdeplot(\n",
    "       data=df, x=num_col, hue=cat_col,\n",
    "       fill=True, common_norm=False,\n",
    "       alpha=.5, linewidth=0, ax=ax\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f'{num_col} by {cat_col}')\n",
    "    return ax\n",
    "\n",
    "\n",
    "def visualize_two_cols_nn(col_name1, col_name2, df_name=None, a_df=None):\n",
    "    \"\"\"\n",
    "    Generates a histogram plot of the different values colored by category.\n",
    "    \"\"\"\n",
    "    a_df = _get_df(a_df)\n",
    "    df_name = _get_df_name(df_name)\n",
    "\n",
    "    df = a_df[[col_name1, col_name2]]\n",
    "    df[col_name1] = pd.to_numeric(df[col_name1], errors='coerce')\n",
    "    df[col_name2] = pd.to_numeric(df[col_name2], errors='coerce')\n",
    "    df = df.dropna()\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.scatterplot(\n",
    "        data=df,\n",
    "        x=col_name1,\n",
    "        y=col_name2,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(f'{col_name1} by {col_name2}')\n",
    "    return ax\n",
    "\n",
    "\n",
    "def visualize_two_cols(col_name1, col_name2, col_types, df_name=None, a_df=None):\n",
    "    \"\"\"\n",
    "    Generates a stacked bar plot for the counts of two categorical columns.\n",
    "\n",
    "    Parameters:\n",
    "        col_name1 (str): The first column to group by.\n",
    "        col_name2 (str): The second column to group by.\n",
    "        df_name (DataFrame): Name of dataframe if different than g_working_df.\n",
    "        a_df (DataFrame): Dataframe if differnt than g_working_df\n",
    "    \"\"\"\n",
    "\n",
    "    a_df = _get_df(a_df)\n",
    "    df_name = _get_df_name(df_name)\n",
    "\n",
    "    _validate_column(col_name1, a_df)\n",
    "    _validate_column(col_name2, a_df)\n",
    "\n",
    "    type_of1 = col_types[col_name1]\n",
    "    type_of2 = col_types[col_name2]\n",
    "    print(f'Column {col_name1} thought to be {type_of1}.\\nColumn {col_name2} thought to be {type_of2}.')\n",
    "\n",
    "    if type_of1 == 'categorical' and type_of2 == 'categorical':\n",
    "        visualize_two_cols_cc(col_name1, col_name2, a_df)\n",
    "    elif type_of1 == 'categorical' and type_of2 == 'numeric':\n",
    "        visualize_two_cols_cn(col_name1, col_name2, a_df)\n",
    "    elif type_of1 == 'numeric' and type_of2 == 'categorical':\n",
    "        visualize_two_cols_cn(col_name2, col_name1, a_df)\n",
    "    elif type_of1 == 'numeric' and type_of2 == 'numeric':\n",
    "        visualize_two_cols_nn(col_name1, col_name2, a_df)\n",
    "    else:\n",
    "        print('Invalid column types.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a73b1b6-745e-4a9f-9a1a-1c3abe3fa219",
   "metadata": {},
   "source": [
    "## Explore and Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584e5e3c-4068-4f56-abea-dab370548598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AB: modified many of these\n",
    "def _explore_col(col_name, df_name=None, a_df=None):\n",
    "    full_prompt = _get_explore_col_prompt(col_name)\n",
    "    return _ask(full_prompt, df_name, a_df)\n",
    "\n",
    "\n",
    "@stateful\n",
    "def explore_col(col_name, df_name=None, a_df=None):\n",
    "\n",
    "    df_name = _get_df_name(df_name)\n",
    "    a_df = _get_df(a_df)\n",
    "    _validate_column(col_name, a_df, df_name)\n",
    "\n",
    "    _, result = _explore_col(col_name, df_name, a_df)\n",
    "    result_txt = _get_result_text(result)\n",
    "    _set_query_and_output_to_raw(result_txt)\n",
    "\n",
    "\n",
    "def _run_predefined_prompts(user_prompt):\n",
    "    unrecognized = False\n",
    "    \n",
    "    # Note, this is a full prompt, a not prompt prefix, or\n",
    "    # else we might erroneously catch the user trying to \n",
    "    # start a request for something else\n",
    "    if user_prompt == g_summarize_statement:\n",
    "        summarize()\n",
    "    elif user_prompt.startswith(g_summarize_col_statement):\n",
    "        col_name = _remove_known_str(user_prompt, g_summarize_col_statement)\n",
    "        summarize_col(col_name)\n",
    "    elif user_prompt.startswith(g_explore_col_statement):\n",
    "        col_name = _remove_known_str(user_prompt, g_explore_col_statement)\n",
    "        explore_col(col_name)        \n",
    "    else:\n",
    "        unrecognized = True\n",
    "    return unrecognized\n",
    "    \n",
    "\n",
    "@stateful\n",
    "# DP: modified to optionally not track the calls to get column type\n",
    "def ask(user_prompt, df_name=None, a_df=None, show_prompt=False, track=True):  \n",
    "    orig_prompt = user_prompt\n",
    "\n",
    "    try:\n",
    "        user_prompt = _change_first_char(user_prompt, upper=False)\n",
    "        unrecognized = _run_predefined_prompts(user_prompt)\n",
    "    \n",
    "        if unrecognized:\n",
    "            # otherwise, ask AI\n",
    "            prompt, result = _ask(user_prompt, df_name, a_df)  \n",
    "            output = _get_ask_txt(result)\n",
    "        \n",
    "            if show_prompt:\n",
    "                output = prompt + \"\\n\\n\" + output\n",
    "            if track:\n",
    "                _save_state(_g_last_code_out, output, _g_LAST_CODE_NAME)\n",
    "            #print(output)\n",
    "\n",
    "            _set_query_and_output_to_raw(output)\n",
    "\n",
    "    #except Exception as ex:\n",
    "    #    print(f\"I don't understand the prompt:\\n{orig_prompt}\")\n",
    "    finally:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6274fd-b43f-4dad-83fd-f6ff5eabfad8",
   "metadata": {},
   "source": [
    "## Widget creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1013f04f-a77a-4512-a367-54ca983a3783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://github.com/jupyter-widgets/ipywidgets/issues/2962#issuecomment-724210454\n",
    "class ConfirmationButton(widgets.HBox):\n",
    "    button_style = Any(default_value='')\n",
    "    description = Unicode()\n",
    "    disabled = Bool()\n",
    "    icon = Unicode()\n",
    "    layout = Any()\n",
    "    style = Any()\n",
    "    tooltip = Unicode()\n",
    "    \n",
    "    def  __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._button = widgets.Button(**kwargs)\n",
    "        self._confirm_btn = widgets.Button(description='Confirm', icon='check', \n",
    "                                           button_style='success', layout=dict(width='auto'))\n",
    "        self._cancel_btn = widgets.Button(description='Cancel', icon='times', \n",
    "                                          button_style='warning', layout=dict(width='auto'))\n",
    "        self._button.on_click(self._on_btn_click)\n",
    "        self._cancel_btn.on_click(self._on_btn_click)\n",
    "        self._confirm_btn.on_click(self._on_btn_click)\n",
    "        self.children = [self._button]\n",
    "        for key in self._button.keys:\n",
    "            if key[0]!='_':\n",
    "                link((self._button,key), (self, key))\n",
    "        \n",
    "    def on_click(self, *args, **kwargs):\n",
    "        self._confirm_btn.on_click(*args, **kwargs)\n",
    "        \n",
    "    def _on_btn_click(self, b):\n",
    "        if b==self._button:\n",
    "            self.children = [self._confirm_btn, self._cancel_btn]\n",
    "        else:\n",
    "            self.children = [self._button]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aedcf5-e567-425c-91b5-695b09b7b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_cell(a_button=None):\n",
    "    #_g_front_end.commands.execute('notebook:insert-cell-below')\n",
    "    #_g_front_end.commands.execute('notebook:move-cell-up')  \n",
    "    _insert_and_run(None, move_up=True)\n",
    "    \n",
    "def _revert_df_from_button(a_button=None, move_up=True):\n",
    "    statement = revert_df()\n",
    "    _insert_and_run(statement, move_up=move_up) \n",
    "\n",
    "\n",
    "def _copy_or_run_suggestion(a_button, move_up, copy_only=True):\n",
    "    statement = _get_last_state(_g_last_code_out)\n",
    "    statement = statement if statement else f'There is no {_g_LAST_CODE_NAME} stored.' \n",
    "    if copy_only:\n",
    "        _insert_and_populate(statement, move_up=move_up)\n",
    "    else:\n",
    "        _insert_and_run(statement, move_up=move_up)  \n",
    "\n",
    "@stateful\n",
    "def copy_suggestion(a_button=None, move_up=True):\n",
    "    _copy_or_run_suggestion(a_button, move_up, copy_only=True)\n",
    "    _set_query_to_raw(up_twice=False)\n",
    "\n",
    "\n",
    "@stateful\n",
    "def run_suggestion(a_button=None, move_up=True):\n",
    "    _copy_or_run_suggestion(a_button, move_up, copy_only=False)\n",
    "    _set_query_to_raw(up_twice=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb74c17-132d-4b6b-8a9f-192dc7508605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_first_button(a_widget, a_button):\n",
    "    curr_buttons = list(a_widget.children)\n",
    "    curr_buttons.insert(0, a_button)\n",
    "    return tuple(curr_buttons)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9580553a-48d1-48fa-bd03-d5fbba8fc224",
   "metadata": {},
   "outputs": [],
   "source": [
    "_g_add_cell_button = widgets.Button(\n",
    "    description=\"Add Cell\",\n",
    "    button_style=\"primary\",  # full blue\n",
    "    tooltip=\"Add an empty code cell\",\n",
    "    icon=\"plus\"\n",
    ")\n",
    "_g_add_cell_button.on_click(_add_cell)\n",
    "\n",
    "\n",
    "_g_copy_suggestion_button = widgets.Button(\n",
    "    description=\"Copy Suggestion\",\n",
    "    tooltip=\"Copy AI-generated code to a new cell\",\n",
    "    icon=\"copy\"\n",
    ")\n",
    "_g_copy_suggestion_button.style.button_color = 'lightgreen'\n",
    "_g_copy_suggestion_button.on_click(copy_suggestion)\n",
    "\n",
    "\n",
    "_g_run_suggestion_button = widgets.Button(\n",
    "    description=\"Run Suggestion\",\n",
    "    button_style=\"info\",  # light blue\n",
    "    tooltip=\"Run last AI-generated code in a new cell\",\n",
    "    icon=\"run\"\n",
    ")\n",
    "_g_run_suggestion_button.on_click(run_suggestion)\n",
    "\n",
    "_g_undo_button = ConfirmationButton(\n",
    "    description='Revert Df', \n",
    "    tooltip=\"Revert dataframe to last stored state\",\n",
    "    button_style=\"warning\"  # red\n",
    ")\n",
    "_g_undo_button.on_click(_revert_df_from_button)\n",
    "\n",
    "\n",
    "g_buttons = widgets.HBox([_g_add_cell_button, _g_copy_suggestion_button, _g_run_suggestion_button, _g_undo_button])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c86df86-172a-4dcb-bcd7-f87c3f9cb70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_g_unrecognized_msg = \"I didn't catch that.\"\n",
    "\n",
    "if g_use_speech:\n",
    "    _g_speech_recognizer = speech_recog.Recognizer()\n",
    "    \n",
    "    # lifted from https://youtu.be/2kSPbH4jWME\n",
    "    _g_record_button = widgets.Button(\n",
    "        description=\"Record\",\n",
    "        disabled=False,\n",
    "        button_style=\"success\",  # full green\n",
    "        icon=\"microphone\"\n",
    "    )\n",
    "    \n",
    "    def _record_audio(a_button):\n",
    "        a_button.description = \"Recording\"\n",
    "        with speech_recog.Microphone() as source: \n",
    "            # listen for 10 seconds for speech to start, \n",
    "            # listen for 10 seconds after speech pauses for it to restart\n",
    "            audio = _g_speech_recognizer.listen(source, 10, 10)\n",
    "        \n",
    "        try:\n",
    "            txt = _g_speech_recognizer.recognize_google(audio)\n",
    "        except speech_recog.UnknownValueError:\n",
    "            txt = f\"print('{_g_unrecognized_msg}')\"\n",
    "    \n",
    "        a_button.description = \"Record\"\n",
    "\n",
    "        if txt == g_add_cell_statement:\n",
    "            _add_cell()\n",
    "        elif txt == g_run_last_statement:\n",
    "            run_suggestion()\n",
    "        elif txt == g_revert_df_statement:\n",
    "            _revert_df()\n",
    "        else:\n",
    "            statement = f\"ask('{txt}')\"\n",
    "            _insert_and_run(statement)\n",
    "\n",
    "\n",
    "    _g_record_button.on_click(_record_audio)\n",
    "    g_buttons.children = _add_first_button(g_buttons, _g_record_button)\n",
    "# end if use speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280758df-3728-4784-b989-74df20b2b9ce",
   "metadata": {},
   "source": [
    "## Dataframe helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a1bde4-e81c-45f1-9749-3580814f5163",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_TAB_SEP = \"tab\"\n",
    "g_COMMA_SEP = \"comma\"\n",
    "\n",
    "#pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "def load_df(fp, sep_name=g_TAB_SEP, dtype=\"str\", override=False):\n",
    "    global g_working_df\n",
    "    if not override:\n",
    "        proposed_sep = None\n",
    "        if fp.endswith(\".csv\") and sep_name==g_TAB_SEP:\n",
    "            proposed_sep = g_COMMA_SEP\n",
    "        elif (fp.endswith(\".txt\") or fp.endswith(\".tsv\")) and sep_name==g_COMMA_SEP:\n",
    "            proposed_sep = g_TAB_SEP\n",
    "    \n",
    "        if proposed_sep is not None:\n",
    "            msg = (f\"Are you sure this file shouldn't be loaded with a {proposed_sep}?\\n\"\n",
    "                   f\"If it should be, rerun `load_df` with the `sep_name` parameter \"\n",
    "                   f\"set to {proposed_sep}.\\n\"\n",
    "                   f\"If not, you can run `load_df` with the `override` parameter \"\n",
    "                   f\"set to True.\")\n",
    "            print(msg)\n",
    "            return\n",
    "\n",
    "    real_sep = None\n",
    "    if sep_name == g_TAB_SEP:\n",
    "        real_sep = \"\\t\"\n",
    "    elif sep_name == g_COMMA_SEP:\n",
    "        real_sep = \",\"\n",
    "    else:\n",
    "        msg = (f\"'{sep_name}' is an unrecognized separator type.  Please choose one of the \"\n",
    "               f\" following recognized separators: {[g_TAB_SEP, g_COMMA_SEP]}.\")\n",
    "        print(msg)\n",
    "        return \n",
    "\n",
    "    loaded_df = pd.read_csv(fp, sep=real_sep, dtype=dtype)\n",
    "\n",
    "    if not override:\n",
    "        if len(g_working_df) > 0:\n",
    "            msg = (\"This load will overwrite the current contents of g_working_df.\\n\"\n",
    "                   \"If you don't want to load these contents, copy g_working_df to another \"\n",
    "                   \"dataframe variable before running this.\\n\"\n",
    "                   \"If you really don't care, rerun `load_df` with the `override` \"\n",
    "                   \"parameter set to True.\")\n",
    "            print(msg)\n",
    "            return\n",
    "            \n",
    "    g_working_df = loaded_df\n",
    "    store_working_df()\n",
    "    return g_working_df\n",
    "    #display_df()\n",
    "\n",
    "\n",
    "@stateful\n",
    "def display_df():\n",
    "    if g_working_df.shape[0] > 300 or g_working_df.shape[1] > 100:\n",
    "        print(\"Dataframe is too large for interactive display; this is a partial visualization.\")\n",
    "        display(g_working_df)\n",
    "    else:\n",
    "        show(\n",
    "            g_working_df,\n",
    "            layout={\"top1\": \"searchPanes\"},\n",
    "            searchPanes={\"layout\": \"columns-3\", \"cascadePanes\": True, \"columns\": [0]},  # not sure how to use this columns setting\n",
    "            lengthMenu=[100, 200, 300],\n",
    "            buttons=[\n",
    "                \"colvis\",\n",
    "                {\"extend\": \"csvHtml5\", \"title\": \"metadata\"},  # TODO: will want to autogenerate this name\n",
    "                {\"extend\": \"excelHtml5\", \"title\": \"metadata\"},\n",
    "            ],\n",
    "            fixedColumns={\"start\": 1},\n",
    "            scrollX=True,\n",
    "            scrollY=\"200px\", scrollCollapse=True, paging=False,\n",
    "        )\n",
    "\n",
    "\n",
    "# conda install dtale -c conda-forge\n",
    "#import dtale\n",
    "#d = dtale.show(g_working_df, host='localhost', hide_drop_rows=True, hide_header_editor=True, allow_cell_edits=False, hide_column_menus=True)\n",
    "#d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07897dc-099c-4ab7-9208-04cbbef5a335",
   "metadata": {},
   "source": [
    "## Interactive investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00980037-d3a5-473e-878f-8a7c8cdeb173",
   "metadata": {},
   "source": [
    "To talk to the AI, either type your request within the function `ask()` or, if voice control is enabled, clicking the record button (which will call the `ask` function with your spoken input).\n",
    "\n",
    "Special statements:\n",
    "* `check column named <column name>`: asks the AI to draw summarized conclusions about the column and its contents.\n",
    "    * Example: `ask('check column named time initiate breast')`\n",
    "* `write code to <description of action>`: asks the AI to limit its responses to code and comments only.\n",
    "    * Example: `ask('write code to replace within one hour of birth with less one hour')`\n",
    "* `now run it`: asks the AI to run the last code it wrote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376e7168-3f82-4bd5-aa26-3e0fb187f16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "external_metadata_fp = \"./proof_of_concept_nb/15612_expanded_sample_info_10112024_PRJNA277905.csv\"\n",
    "qiita_metadata_fp = \"./proof_of_concept_nb/15612_20240714-052306.txt\"\n",
    "study_config_fp = './proof_of_concept_nb/trpca_study.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ecea5-4d33-4108-ae41-a42f6df69119",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_df(external_metadata_fp, sep_name=\"comma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f5940f-ba64-4091-bb4e-048361ece086",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEMPORARY: Examples of code that preserves AI results while preventing their (non-deterministic) rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f8a0c1-27c8-452b-8878-0c845d457213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: summarize table using recognized phrase\n",
    "ask('summarize table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc422921-6bcd-433f-9c20-6ca40f0ba37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: summarize table using direct function call\n",
    "summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd936b37-3c0e-482a-b4d7-0307c2bb7070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: summarize a column using recognized phrase\n",
    "ask(\"summarize column named LibraryID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3192a0f2-e9d7-4f7b-8299-cbda2a546e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: summarize a column using direct function call\n",
    "summarize_col(\"Gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41face8-5b51-48d0-a7ab-990f6ea77381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: explore a column using recognized phrase\n",
    "ask(\"explore column named Gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87675ad-ede7-4151-9cf3-50d9d27f25c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: explore a column using direct function call\n",
    "explore_col(\"Gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5527f2b3-a034-4f38-b1a1-874a6f2d0b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: ask arbitrary question\n",
    "ask(\"Describe how best to check an id column for uniqueness.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33f94b5-7ae3-4fa1-9a9a-60e94dfcb8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: write arbitrary code\n",
    "ask(\"write code to change name of Gender column to gender\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aa26db-4c4e-4fc6-847a-ca1a7ab0ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: run suggested code\n",
    "run_suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d095096-29c1-40b4-a6ac-f7705e755d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: write arbitrary code #2\n",
    "ask(\"write code to change name of LibraryID column to sample_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e8eee0-a22f-4701-aaa5-38ce1ee815ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: copy but do not run suggestion\n",
    "copy_suggestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9186f3-1b79-445e-8102-9d8187634d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11c2aa2-95b8-4c2f-b1da-078400a32ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(g_buttons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933f2e77-f4cb-4b6e-85b0-128e78b95f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(g_working_df[g_working_df['sampletype_shorthand'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3400225-884c-4ece-b7b3-15f8d6e95dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiimp_cols = qiimp.get_reserved_cols(g_working_df, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cf7e22-7029-4351-b433-3fa498429743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiimp.find_common_col_names(g_working_df.columns, qiimp_cols, [qiimp.HOSTTYPE_SHORTHAND_KEY, #qiimp.SAMPLETYPE_SHORTHAND_KEY], [qiimp.HOSTTYPE_SHORTHAND_KEY, qiimp.SAMPLETYPE_SHORTHAND_KEY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4fd523-ae64-4b05-9eb0-49fa317a3173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ask(\"Write code to rename the 'sex' and 'sample_name' columns with the prefix '_external' at the end.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c030f9-3cd4-4526-9b9c-8429fe99d5e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94edf629-63d4-489d-b350-a15060a4e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#g_working_df['sex'] = g_working_df['sex_external'].apply(qiimp.standardize_input_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67efb30-23a9-4baa-9fc0-fcde3c70a988",
   "metadata": {},
   "outputs": [],
   "source": [
    "#g_working_df['host_life_stage'] = g_working_df['host_age'].apply(qiimp.set_life_stage_from_age_yrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ff54c9-725b-410d-ac83-1c2a318261f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I know these values for this particular study.\n",
    "# Note it had only healthy participants\n",
    "#g_working_df[\"has_skin_disorder\"] = False\n",
    "#g_working_df[\"lesional_status\"] = \"not applicable\"  \n",
    "#g_working_df[\"ethnicity\"] = \"not provided\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cb3600-6303-46ae-a1f9-fc60924fabde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ext_metadata_df = g_working_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdbefb2-9a4b-4907-b320-c74827e26fa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load_df(qiita_metadata_fp, sep_name=\"tab\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c42bfe-90ff-418c-92f9-5dd9085581fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda91deb-1dfe-4c3c-ad11-938d4d5e59fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiimp.find_common_df_cols(g_working_df, ext_metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211729de-d08c-4996-8942-48a0ba1efc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#g_working_df.rename(columns={'host_age': 'host_age_external'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a742a00-e49b-448f-a32f-59401ff8e806",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiimp.find_common_df_cols(g_working_df, ext_metadata_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e9cbd3-d52f-467a-adab-7bfce9f9c789",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#merged_df = qiimp.merge_many_to_one_metadata(g_working_df, ext_metadata_df, \"sample_alias\", \"sample_name_external\", \"qiita\", \"external\", \"outer\")\n",
    "#merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416a6f41-69d8-4219-8577-ed7ea25fb4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df[merged_df[\"sample_name\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d07a71-fedd-44a0-805f-22b5d35c56f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df[merged_df[\"sample_alias\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf78c317-cf88-40e7-8282-40aeec1d359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#g_working_df = merged_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b1775-d4d2-4db0-a694-764b714211ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extended_df, validation_msgs = qiimp.get_extended_metadata_from_df_and_yaml(g_working_df, study_config_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0250b9-d955-462f-a97d-b09217e0e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extended_df[extended_df['qc_note'].notnull() & (extended_df['qc_note'] != '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19be9301-1c20-4d6a-8319-7cee37b22db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3c60d6-c11d-4e56-be0e-02d48b96aef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#qiimp.write_metadata_results(extended_df, validation_msgs, '/Users/abirmingham/Desktop/trpca', \"15613_merged_metadata_standardized\", suppress_empty_fails=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metagpt_langchain",
   "language": "python",
   "name": "metagpt_langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
